data_description.md
ğŸ“Œ Dataset Overview

This dataset is a synthetic, time-ordered streaming dataset designed to simulate real-world model drift scenarios in deployed machine learning systems.

It is intentionally constructed to evaluate:

Concept drift detection

Subgroup (localized) drift

Model confidence degradation

Performance decay in fixed (non-retrained) models

âš ï¸ Important:
This dataset is strictly sequential and must never be shuffled.

ğŸ¯ Design Goals

The dataset satisfies the following critical properties:

Time-ordered data arrival

Gradual and controlled drift

Localized subgroup drift

Hidden ground-truth labels

Hidden subgroup membership

Increasing uncertainty over time (confidence collapse)

This mirrors real production systems, where labels and subgroup identities are not available at inference time.

â± Time Characteristics
Property	Description
Time column	time
Ordering	Strictly increasing
Arrival	Sequential (streaming)
Shuffling	âŒ Not allowed

Each row represents one time step in a live data stream.

ğŸ§  Feature Description

The dataset contains 6 continuous features:

Feature Name	Description
feature_1_activity_score	Represents user/system activity intensity
feature_2_reliability	Measures stability or reliability of behavior
feature_3_complexity	Captures task or input complexity
feature_4_temporal_behavior	Encodes temporal usage patterns
feature_5_interaction_depth	Reflects depth of interactions
feature_6_variability	Measures randomness or fluctuation

All features are numeric and initially follow a normal distribution.

ğŸŒŠ Drift Scenarios
1ï¸âƒ£ Global Gradual Drift

Starts after time = 300

Affects all samples

Slowly shifts feature distributions

Mimics natural environmental or user-behavior changes

ğŸ“ˆ Drift is continuous and smooth, not abrupt.

2ï¸âƒ£ Localized Subgroup Drift

Starts after time = 600

Affects only one hidden cluster

Alters specific features:

feature_3_complexity

feature_6_variability

ğŸ¯ This simulates bias or failure emerging in a specific population segment, while global metrics may still look stable.

3ï¸âƒ£ Confidence Collapse Scenario

Noise increases gradually over time

Features move closer to decision boundaries

Model predictions become less stable

âš ï¸ This causes confidence degradation without immediate accuracy collapse, which is difficult to detect using standard metrics.

ğŸ§© Hidden Structure (Evaluation Only)
Cluster Membership
Column	Purpose
cluster_id	Hidden subgroup identifier

Used only for offline analysis

Never exposed to the deployed model

Enables evaluation of subgroup-specific drift

Ground Truth Labels
Column	Purpose
true_label	Actual class label

Generated using a fixed decision function

Not available during inference

Used only for post-hoc evaluation

This simulates real-world production systems where labels arrive late or not at all.

ğŸš« What the Model Can See

At inference time, the deployed model has access to:

âœ… Feature columns
âœ… Time index

âŒ true_label
âŒ cluster_id

This separation enforces realistic monitoring constraints.

ğŸ“¦ File Information
Property	Value
Format	CSV
Filename	dataset.csv
Rows	1500
Features	6
Shuffling	âŒ Never
ğŸ§ª Intended Usage

This dataset is designed for:

Streaming inference pipelines

Drift detection research

Model monitoring demos

Hackathon / judge evaluation scenarios

It is not intended for static supervised learning benchmarks.

âš ï¸ Important Constraints

Do NOT retrain the model during streaming

Do NOT shuffle the dataset

Do NOT use labels for monitoring logic

Drift must be detected without supervision